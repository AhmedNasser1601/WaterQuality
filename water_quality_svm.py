# -*- coding: utf-8 -*-
"""water quality SVM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19-cWsamC90rp5xmkM7x6URe4scJ-ZUeM
"""

#svm 
#water quality dataset
import csv
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn import metrics
#from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler

#loading csv file
file_path ='waterQuality1.csv'
dataset=pd.read_csv(file_path)
dataset.head()

#preprocessing 
print(dataset.isnull().sum())# to see the columns that contain nulls

dataset = dataset[dataset['is_safe'] != '#NUM!']
dataset['is_safe'] = dataset['is_safe'].astype(int)

#svm
x = dataset.drop('is_safe', axis=1)#to designate that you want to drop a column
y =dataset.is_safe

#splitting the data
X_train, X_test, y_train, y_test = train_test_split(x, y,test_size=0.2,random_state=42)

#create the svm classifier
clf=svm.SVC(kernel='linear')

#train the model
clf.fit(X_train,y_train)
#predict the response for dataset
y_pred=clf.predict(X_test) 

#accurracy
print("Accuracy:", metrics.accuracy_score(y_test,y_pred))

import csv
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn import metrics
#from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
#loading csv file
file_path ='/content/water_potability.csv'
dataset=pd.read_csv(file_path)
dataset.head()

#preprocessing 
#dataset.drop(['ph','Sulfate'],axis=1, inplace=True)
dataset.dropna(inplace=True)

#supstitute by the mean
#dataset["ph"].fillna(value = dataset["ph"].median(), inplace =True)
#dataset['Trihalomethanes'].fillna(value = dataset['Trihalomethanes'].median(), inplace =True)
#dataset["Sulfate"].fillna(value = dataset["Sulfate"].median(), inplace =True)

#Model
X = dataset.drop('Potability',axis=1)
Y = dataset.Potability

#splitting the data
X_train, X_test, y_train, y_test = train_test_split(X, Y,test_size=0.2,random_state=42)

#create the svm classifier
clf=svm.SVC(kernel='linear')

#train the model
clf.fit(X_train,y_train)
#predict the response for dataset
y_pred=clf.predict(X_test) 

#accurracy
print("Accuracy:", metrics.accuracy_score(y_test,y_pred))

from sklearn.linear_model import SGDClassifier
sgd=SGDClassifier(loss='modified_huber',shuffle=True,random_state=42)
sgd.fit(X_train,y_train)
y_pred=sgd.predict(X_test)
print("Accuracy:", metrics.accuracy_score(y_test,y_pred))

from sklearn.ensemble import RandomForestClassifier
#dataset.drop(['ph','Sulfate'],axis=1, inplace=True)
rfm=RandomForestClassifier(n_estimators=70,oob_score=True,n_jobs=-1,random_state=42,max_features=None,min_samples_leaf=30)
rfm.fit(X_train,y_train)
y_pred=rfm.predict(X_test)
print("Accuracy:", metrics.accuracy_score(y_test,y_pred))

import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.ensemble import GradientBoostingClassifier

X = dataset.drop('Potability',axis=1)
Y = dataset.Potability

#scale the data
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X)
X_test = scaler.transform(X)
#splitting the data
X_train, X_val, y_train, y_val = train_test_split(X_train, Y,test_size=0.2,random_state=42)

#Now we can try setting different learning rates, so that we can compare the performance of the classifier's performance at different learning rates.
lr_list = [0.4,0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]
for learning_rate in lr_list:
    gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)
    gb_clf.fit(X_train, y_train)

    print("Learning rate: ", learning_rate)
    print("Accuracy score (training): {0:.3f}".format(gb_clf.score(X_train, y_train)))
    print("Accuracy score (validation): {0:.3f}".format(gb_clf.score(X_val, y_val)))
    print("")